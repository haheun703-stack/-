"""DART ì´ë²¤íŠ¸ ë“œë¦¬ë¸ ì‹œê·¸ë„ â€” Timefolio ë²¤ì¹˜ë§ˆí¬ ì „ëµ 3

ê¸°ì¡´ crawl_dart_disclosure.pyì˜ ì¶œë ¥(dart_disclosures.json)ì„
ì´ë²¤íŠ¸ ë“œë¦¬ë¸ ë§¤ë§¤ ì‹œê·¸ë„ë¡œ ë³€í™˜í•œë‹¤.

Tier1/Tier2 ê³µì‹œì—ì„œ ë§¤ë§¤ ì•¡ì…˜ ê°€ëŠ¥í•œ ì‹œê·¸ë„ì„ ìƒì„±í•˜ê³ ,
ê¸°ìˆ ì  ì§€í‘œë¡œ ë³´ì •í•˜ì—¬ ìµœì¢… ì ìˆ˜ë¥¼ ì‚°ì¶œí•œë‹¤.

ì…ë ¥:
  - data/dart_disclosures.json (crawl_dart_disclosure.py ì¶œë ¥)
  - data/processed/*.parquet (ê¸°ìˆ ì  ì§€í‘œ)
  - stock_data_daily/*.csv (ì¢…ëª©ëª… ë§¤í•‘)

ì¶œë ¥:
  - data/dart_event_signals.json

Usage:
    python scripts/dart_event_signal.py
"""

from __future__ import annotations

import json
import logging
import sys
from datetime import datetime
from pathlib import Path

import numpy as np
import pandas as pd

PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%H:%M:%S",
    handlers=[logging.StreamHandler(sys.stdout)],
)
logger = logging.getLogger(__name__)

DATA_DIR = PROJECT_ROOT / "data"
PROCESSED_DIR = DATA_DIR / "processed"
CSV_DIR = PROJECT_ROOT / "stock_data_daily"
DART_JSON = DATA_DIR / "dart_disclosures.json"
OUTPUT_PATH = DATA_DIR / "dart_event_signals.json"

# â”€â”€ ì´ë²¤íŠ¸â†’ì ìˆ˜ ë§¤í•‘ â”€â”€
BUY_EVENTS = {
    "ìê¸°ì£¼ì‹ì·¨ë“": 20,
    "ìê¸°ì£¼ì‹ì²˜ë¶„": -5,   # ì²˜ë¶„ì€ ë§ˆì´ë„ˆìŠ¤
    "ê³µê¸‰ê³„ì•½ì²´ê²°": 15,
    "ìˆ˜ì£¼": 15,
    "ëŒ€ê·œëª¨ë‚´ë¶€ê±°ë˜": 10,
    "íƒ€ë²•ì¸ì£¼ì‹ë°ì¶œìì¦ê¶Œì·¨ë“ê²°ì •": 10,
    "ë°°ë‹¹": 10,
    "ë§¤ì¶œì•¡ë˜ëŠ”ì†ìµêµ¬ì¡°": 12,
    "ì ì •ì‹¤ì ": 12,
    "ì‚¬ì—…ë³´ê³ ì„œ": 8,
    "ë°˜ê¸°ë³´ê³ ì„œ": 8,
    "ë¶„ê¸°ë³´ê³ ì„œ": 8,
    "íŠ¹í—ˆ": 10,
    "ë¼ì´ì„ ìŠ¤": 10,
    "ê¸°ìˆ ì´ì „": 10,
    "FDA": 15,
    "ì„ìƒ": 12,
    "ìŠ¹ì¸": 12,
    "ë¬´ìƒì¦ì": 8,
}

WATCH_EVENTS = {
    "ìµœëŒ€ì£¼ì£¼ë³€ê²½": 5,
    "í•©ë³‘": 5,
    "ë¶„í• ": 5,
    "ì¸ìˆ˜": 5,
    "ê³µê°œë§¤ìˆ˜": 5,
    "ì£¼ì‹êµí™˜": 5,
    "ì£¼ì‹ì´ì „": 5,
}

AVOID_EVENTS = {
    "ìœ ìƒì¦ì": -15,
    "ì „í™˜ì‚¬ì±„": -10,
    "ì‹ ì£¼ì¸ìˆ˜ê¶Œë¶€ì‚¬ì±„": -10,
    "ê´€ë¦¬ì¢…ëª©": -30,
    "ê±°ë˜ì •ì§€": -30,
    "ìƒì¥íì§€": -30,
    "íšŒìƒì ˆì°¨": -25,
    "íŒŒì‚°": -30,
}


def build_name_map() -> dict[str, str]:
    """CSV íŒŒì¼ëª…ì—ì„œ ì¢…ëª©ì½”ë“œâ†’ì´ë¦„ ë§¤í•‘"""
    name_map = {}
    for csv in CSV_DIR.glob("*.csv"):
        parts = csv.stem.rsplit("_", 1)
        if len(parts) == 2:
            name_map[parts[1]] = parts[0]
    return name_map


def get_parquet_data(ticker: str) -> dict | None:
    """parquetì—ì„œ ìµœì‹  ê¸°ìˆ ì  ì§€í‘œ ì¶”ì¶œ (ê°„ì†Œí™” ë²„ì „)"""
    pq_path = PROCESSED_DIR / f"{ticker}.parquet"
    if not pq_path.exists():
        return None
    try:
        df = pd.read_parquet(pq_path).tail(10)
        if len(df) < 3:
            return None
        last = df.iloc[-1]
        close = float(last.get("close", 0))

        # ì™¸ì¸/ê¸°ê´€ 5ì¼ í•©ì‚°
        f5 = float(np.nansum(df.tail(5)["ì™¸êµ­ì¸í•©ê³„"].values)) if "ì™¸êµ­ì¸í•©ê³„" in df.columns else 0
        i5 = float(np.nansum(df.tail(5)["ê¸°ê´€í•©ê³„"].values)) if "ê¸°ê´€í•©ê³„" in df.columns else 0

        return {
            "close": close,
            "rsi": float(last.get("rsi_14", 50)),
            "adx": float(last.get("adx_14", 20)),
            "bb_pos": float(last.get("bb_position", 50)),
            "foreign_5d": f5,
            "inst_5d": i5,
        }
    except Exception as e:
        logger.warning("parquet ì½ê¸° ì‹¤íŒ¨ %s: %s", ticker, e)
        return None


def score_event(disclosure: dict, parquet_data: dict | None) -> dict | None:
    """DART ê³µì‹œ â†’ ë§¤ë§¤ ì‹œê·¸ë„ + ì ìˆ˜"""
    keyword = disclosure.get("keyword", "")
    tier = disclosure.get("tier", "")
    stock_code = disclosure.get("stock_code", "").strip()
    corp_name = disclosure.get("corp_name", "")

    if not keyword or not stock_code:
        return None

    # ì´ë²¤íŠ¸ ê¸°ë³¸ ì ìˆ˜ + ì•¡ì…˜ íŒì •
    if keyword in AVOID_EVENTS:
        base_score = AVOID_EVENTS[keyword]
        action = "AVOID"
    elif keyword in BUY_EVENTS:
        base_score = BUY_EVENTS[keyword]
        action = "BUY"
    elif keyword in WATCH_EVENTS:
        base_score = WATCH_EVENTS[keyword]
        action = "WATCH"
    else:
        # ë§¤í•‘ë˜ì§€ ì•Šì€ í‚¤ì›Œë“œ â€” tierì— ë”°ë¼ ê¸°ë³¸ê°’
        if tier == "tier1_ì¦‰ì‹œ":
            base_score = 8
            action = "WATCH"
        elif tier == "tier2_ì¤‘ìš”":
            base_score = 5
            action = "WATCH"
        else:
            return None  # tier3 ì´í•˜ ë¬´ì‹œ

    event_score = base_score

    # ê¸°ìˆ ì  ë³´ì • (BUY/WATCHë§Œ)
    rsi = 50
    if parquet_data and action in ("BUY", "WATCH"):
        rsi = parquet_data.get("rsi", 50)
        # RSI ê³¼ì—´ì´ë©´ ë§¤ìˆ˜ ì‹œê·¸ë„ ê°ì 
        if rsi > 70:
            event_score = max(event_score - 10, 0)
        elif rsi > 60:
            event_score = max(event_score - 3, 0)

        # ìˆ˜ê¸‰ ë³´ì •: ì™¸ì¸+ê¸°ê´€ ìˆœë§¤ìˆ˜ë©´ ê°€ì‚°
        if parquet_data.get("foreign_5d", 0) > 0 and parquet_data.get("inst_5d", 0) > 0:
            event_score += 5
        elif parquet_data.get("foreign_5d", 0) > 0:
            event_score += 2

    return {
        "ticker": stock_code,
        "name": corp_name,
        "event": keyword,
        "report_nm": disclosure.get("report_nm", "")[:60],
        "tier": tier,
        "action": action,
        "event_score": event_score,
        "rsi": round(rsi, 1),
        "url": disclosure.get("url", ""),
    }


def main():
    logger.info("=" * 60)
    logger.info("  DART ì´ë²¤íŠ¸ ë“œë¦¬ë¸ ì‹œê·¸ë„ â€” ì „ëµ 3")
    logger.info("=" * 60)

    # DART ê³µì‹œ ë¡œë“œ
    if not DART_JSON.exists():
        logger.warning("DART ê³µì‹œ íŒŒì¼ ì—†ìŒ: %s", DART_JSON)
        output = {
            "date": datetime.now().strftime("%Y-%m-%d"),
            "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M"),
            "source_period": "",
            "total_events": 0,
            "actionable_count": 0,
            "signals": [],
            "avoid_list": [],
        }
        OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)
        with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
            json.dump(output, f, ensure_ascii=False, indent=2)
        logger.info("  ë¹ˆ ê²°ê³¼ ì €ì¥: %s", OUTPUT_PATH)
        return

    with open(DART_JSON, encoding="utf-8") as f:
        dart_data = json.load(f)

    name_map = build_name_map()
    source_period = dart_data.get("period", "")

    # tier1 + tier2 + universe_hits í†µí•©
    all_disclosures = []
    seen_keys = set()

    for tier_key in ("tier1", "tier2", "universe_hits"):
        for item in dart_data.get(tier_key, []):
            # ì¤‘ë³µ ì œê±° (ê°™ì€ ì¢…ëª©+ê°™ì€ í‚¤ì›Œë“œ)
            dedup_key = f"{item.get('stock_code')}_{item.get('keyword')}"
            if dedup_key in seen_keys:
                continue
            seen_keys.add(dedup_key)
            all_disclosures.append(item)

    logger.info("  ê³µì‹œ %dê±´ (tier1:%d, tier2:%d, universe:%d)",
                len(all_disclosures),
                dart_data.get("tier1_count", 0),
                dart_data.get("tier2_count", 0),
                dart_data.get("universe_hit_count", 0))

    # ì´ë²¤íŠ¸ ìŠ¤ì½”ì–´ë§
    buy_signals = []
    watch_signals = []
    avoid_list = []

    for disc in all_disclosures:
        stock_code = disc.get("stock_code", "").strip()
        pq_data = get_parquet_data(stock_code) if stock_code else None

        result = score_event(disc, pq_data)
        if not result:
            continue

        # ì¢…ëª©ëª… ë³´ì •
        if not result["name"] and stock_code in name_map:
            result["name"] = name_map[stock_code]

        if result["action"] == "BUY":
            buy_signals.append(result)
        elif result["action"] == "WATCH":
            watch_signals.append(result)
        elif result["action"] == "AVOID":
            avoid_list.append(result)

    # ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    buy_signals.sort(key=lambda x: -x["event_score"])
    watch_signals.sort(key=lambda x: -x["event_score"])

    # í†µí•© ì‹œê·¸ë„ (BUY + WATCH, ìƒìœ„ 20ê±´)
    signals = buy_signals + watch_signals
    signals = signals[:20]

    actionable_count = len(buy_signals)

    # ì¶œë ¥
    output = {
        "date": datetime.now().strftime("%Y-%m-%d"),
        "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M"),
        "source_period": source_period,
        "total_events": len(all_disclosures),
        "actionable_count": actionable_count,
        "signals": signals,
        "avoid_list": avoid_list[:10],
    }

    OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)
    with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    logger.info("â”€â”€ ê²°ê³¼ â”€â”€")
    logger.info("  BUY ì‹œê·¸ë„: %dê±´", len(buy_signals))
    logger.info("  WATCH ì‹œê·¸ë„: %dê±´", len(watch_signals))
    logger.info("  AVOID ì¢…ëª©: %dê±´", len(avoid_list))

    for sig in buy_signals[:5]:
        logger.info("  ğŸŸ¢ BUY  %s(%s) +%dì  â€” %s",
                     sig["name"], sig["ticker"], sig["event_score"], sig["event"])
    for sig in avoid_list[:3]:
        logger.info("  ğŸ”´ AVOID %s(%s) %dì  â€” %s",
                     sig["name"], sig["ticker"], sig["event_score"], sig["event"])

    logger.info("  ì €ì¥: %s", OUTPUT_PATH)


if __name__ == "__main__":
    main()
