"""ìŠˆí¼ì„¹í„° ë¦´ë ˆì´ ë°±í…ŒìŠ¤íŒ… â€” ê³¼ê±° íŒ¨í„´ ê²€ì¦.

"ì„ í–‰ ì„¹í„°ê°€ N% ì´ìƒ ì˜¤ë¥¸ ë‹¤ìŒë‚ , í›„í–‰ ì„¹í„°ê°€ ëª‡% í™•ë¥ ë¡œ ì˜¬ëë‚˜?"
ë¥¼ 2ë…„ì¹˜ ë°ì´í„°ë¡œ ì „ìˆ˜ ê²€ì¦í•˜ì—¬ ìŠ¹ë¥ /ë˜ê·¸/ì‹ ë¢°ë„ë¥¼ ê³„ì‚°í•œë‹¤.

NOTE: ìˆ˜ìµë¥ ì€ ì„¹í„° í‰ê·  ë“±ë½ë¥ (gross). ì‹¤ì œ ë§¤ë§¤ ì‹œ ì™•ë³µ ìˆ˜ìˆ˜ë£Œ(0.03%)
      + ì„¸ê¸ˆ(0.18%) + ìŠ¬ë¦¬í”¼ì§€(â‰ˆ0.5%) â‰ˆ ì´ 0.7%ë¥¼ ì°¨ê°í•´ì•¼ í•¨.

ì…ë ¥:
  - stock_data_daily/*.csv  (2,859ì¢…ëª© ì¼ë´‰)
  - naver_sector_map.csv    (ë„¤ì´ë²„ 79ê°œ ì—…ì¢…)

ì¶œë ¥:
  - data/sector_rotation/relay_patterns.json
    â†’ sector_relay_engine.pyê°€ ì‹ ë¢°ë„ í‘œì‹œì— í™œìš©

ì‚¬ìš©ë²•:
  python scripts/relay_backtest.py              # ì „ì²´ ë°±í…ŒìŠ¤íŒ…
  python scripts/relay_backtest.py --threshold 3 # ë°œí™” ê¸°ì¤€ 3%
  python scripts/relay_backtest.py --days 756    # 3ë…„ì¹˜
"""

from __future__ import annotations

import argparse
import json
import logging
import sys
from datetime import datetime
from pathlib import Path

import numpy as np
import pandas as pd

PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger(__name__)

DATA_DIR = PROJECT_ROOT / "data" / "sector_rotation"
DAILY_DIR = PROJECT_ROOT / "stock_data_daily"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìŠˆí¼ì„¹í„° ì •ì˜ (ë„¤ì´ë²„ 79ê°œ ì—…ì¢… ê¸°ì¤€)
# relay_order: ì„ í–‰(ì•) â†’ í›„í–‰(ë’¤) ìˆœì„œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SUPER_SECTORS = {
    "ê¸ˆìœµ": {
        "sectors": ["ì¦ê¶Œ", "ìƒëª…ë³´í—˜", "ì†í•´ë³´í—˜", "ì€í–‰", "ì¹´ë“œ", "ê¸°íƒ€ê¸ˆìœµ"],
        "relay_pairs": [
            ("ì¦ê¶Œ", "ìƒëª…ë³´í—˜"),
            ("ì¦ê¶Œ", "ì†í•´ë³´í—˜"),
            ("ì¦ê¶Œ", "ì€í–‰"),
            ("ìƒëª…ë³´í—˜", "ì†í•´ë³´í—˜"),
            ("ì€í–‰", "ìƒëª…ë³´í—˜"),
            ("ì€í–‰", "ì†í•´ë³´í—˜"),
        ],
    },
    "IT/ë°˜ë„ì²´": {
        "sectors": ["ë°˜ë„ì²´ì™€ë°˜ë„ì²´ì¥ë¹„", "ë””ìŠ¤í”Œë ˆì´ì¥ë¹„ë°ë¶€í’ˆ", "ì „ìì¥ë¹„ì™€ê¸°ê¸°", "ITì„œë¹„ìŠ¤", "ì†Œí”„íŠ¸ì›¨ì–´"],
        "relay_pairs": [
            ("ë°˜ë„ì²´ì™€ë°˜ë„ì²´ì¥ë¹„", "ë””ìŠ¤í”Œë ˆì´ì¥ë¹„ë°ë¶€í’ˆ"),
            ("ë°˜ë„ì²´ì™€ë°˜ë„ì²´ì¥ë¹„", "ì „ìì¥ë¹„ì™€ê¸°ê¸°"),
            ("ë°˜ë„ì²´ì™€ë°˜ë„ì²´ì¥ë¹„", "ITì„œë¹„ìŠ¤"),
            ("ë””ìŠ¤í”Œë ˆì´ì¥ë¹„ë°ë¶€í’ˆ", "ì „ìì¥ë¹„ì™€ê¸°ê¸°"),
        ],
    },
    "2ì°¨ì „ì§€/ì—ë„ˆì§€": {
        "sectors": ["ì „ê¸°ì œí’ˆ", "í™”í•™", "ì—ë„ˆì§€ì¥ë¹„ë°ì„œë¹„ìŠ¤", "ì„ìœ ì™€ê°€ìŠ¤"],
        "relay_pairs": [
            ("ì „ê¸°ì œí’ˆ", "í™”í•™"),
            ("ì „ê¸°ì œí’ˆ", "ì—ë„ˆì§€ì¥ë¹„ë°ì„œë¹„ìŠ¤"),
            ("í™”í•™", "ì—ë„ˆì§€ì¥ë¹„ë°ì„œë¹„ìŠ¤"),
            ("ì„ìœ ì™€ê°€ìŠ¤", "í™”í•™"),
        ],
    },
    "ë°©ì‚°/ì¡°ì„ ": {
        "sectors": ["ìš°ì£¼í•­ê³µê³¼êµ­ë°©", "ì¡°ì„ ", "ê¸°ê³„"],
        "relay_pairs": [
            ("ìš°ì£¼í•­ê³µê³¼êµ­ë°©", "ì¡°ì„ "),
            ("ìš°ì£¼í•­ê³µê³¼êµ­ë°©", "ê¸°ê³„"),
            ("ì¡°ì„ ", "ê¸°ê³„"),
        ],
    },
    "ê±´ì„¤/ì†Œì¬": {
        "sectors": ["ê±´ì„¤", "ê±´ì¶•ìì¬", "ì² ê°•", "ë¹„ì² ê¸ˆì†"],
        "relay_pairs": [
            ("ê±´ì„¤", "ê±´ì¶•ìì¬"),
            ("ê±´ì„¤", "ì² ê°•"),
            ("ì² ê°•", "ë¹„ì² ê¸ˆì†"),
        ],
    },
    "ì†Œë¹„/ìœ í†µ": {
        "sectors": ["ë°±í™”ì ê³¼ì¼ë°˜ìƒì ", "ì‹í’ˆ", "ìŒë£Œ", "í™”ì¥í’ˆ"],
        "relay_pairs": [
            ("ë°±í™”ì ê³¼ì¼ë°˜ìƒì ", "ì‹í’ˆ"),
            ("ë°±í™”ì ê³¼ì¼ë°˜ìƒì ", "í™”ì¥í’ˆ"),
            ("í™”ì¥í’ˆ", "ì‹í’ˆ"),
        ],
    },
    "ë°”ì´ì˜¤/í—¬ìŠ¤": {
        "sectors": ["ì œì•½", "ìƒë¬¼ê³µí•™", "ê±´ê°•ê´€ë¦¬ì¥ë¹„ì™€ìš©í’ˆ", "ìƒëª…ê³¼í•™ë„êµ¬ë°ì„œë¹„ìŠ¤"],
        "relay_pairs": [
            ("ì œì•½", "ìƒë¬¼ê³µí•™"),
            ("ì œì•½", "ê±´ê°•ê´€ë¦¬ì¥ë¹„ì™€ìš©í’ˆ"),
            ("ìƒë¬¼ê³µí•™", "ê±´ê°•ê´€ë¦¬ì¥ë¹„ì™€ìš©í’ˆ"),
        ],
    },
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. ë°ì´í„° ë¡œë“œ + ì„¹í„°ë³„ ì¼ë³„ ë“±ë½ë¥  ë¹Œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_naver_sector_map() -> dict[str, str]:
    """ë„¤ì´ë²„ ì„¹í„°ë§µ ë¡œë“œ â†’ {ticker: sector}"""
    path = DATA_DIR / "naver_sector_map.csv"
    df = pd.read_csv(path, dtype={"ticker": str})
    return dict(zip(df["ticker"], df["sector"]))


def build_sector_daily_returns(
    ticker_to_sector: dict[str, str],
    min_stocks: int = 3,
) -> pd.DataFrame:
    """ì „ì¢…ëª© CSVì—ì„œ ì„¹í„°ë³„ ì¼ë³„ ë“±ë½ë¥  DataFrame ë¹Œë“œ.

    Returns:
        DataFrame index=date, columns=[sector1_ret, sector1_breadth, sector1_count, ...]
        Wide format â†’ ì´í›„ ì„¹í„°ëª…ìœ¼ë¡œ ì§ì ‘ ì¡°íšŒ
    """
    logger.info("stock_data_daily CSV ë¡œë“œ ì¤‘...")

    # ëª¨ë“  CSVì—ì„œ (ticker, date, close) ìˆ˜ì§‘
    all_closes = {}  # {ticker: Series(dateâ†’close)}
    csv_files = list(DAILY_DIR.glob("*.csv"))
    loaded = 0

    for csv_path in csv_files:
        # íŒŒì¼ëª…: "ì¢…ëª©ëª…_í‹°ì»¤.csv" â†’ rsplitìœ¼ë¡œ í‹°ì»¤ ì¶”ì¶œ
        parts = csv_path.stem.rsplit("_", 1)
        if len(parts) < 2:
            continue
        ticker = parts[-1]
        if ticker not in ticker_to_sector:
            continue
        try:
            df = pd.read_csv(csv_path, usecols=["Date", "Close"], parse_dates=["Date"])
            df = df.dropna().set_index("Date").sort_index()
            if len(df) < 60:
                continue
            all_closes[ticker] = df["Close"]
            loaded += 1
        except Exception:
            continue

    logger.info("CSV ë¡œë“œ ì™„ë£Œ: %dì¢…ëª©", loaded)

    # ì¢…ëª©ë³„ ì¼ë³„ ìˆ˜ìµë¥  ê³„ì‚°
    all_returns = {}  # {ticker: Series(dateâ†’pct_change)}
    for ticker, closes in all_closes.items():
        ret = closes.pct_change() * 100
        all_returns[ticker] = ret.dropna()

    # ì„¹í„°ë³„ ì§‘ê³„
    sectors = set(ticker_to_sector.values())
    sector_groups = {s: [] for s in sectors}
    for ticker, ret_series in all_returns.items():
        sector = ticker_to_sector[ticker]
        sector_groups[sector].append(ret_series)

    # ì„¹í„°ë³„ ì¼ë³„ í‰ê· ìˆ˜ìµë¥  + breadth
    result_frames = []

    for sector, series_list in sector_groups.items():
        if len(series_list) < min_stocks:
            continue

        # DataFrameìœ¼ë¡œ í•©ì¹˜ê¸° (ê³µí†µ ë‚ ì§œ)
        df_combined = pd.DataFrame({f"s{i}": s for i, s in enumerate(series_list)})
        df_combined = df_combined.dropna(thresh=max(3, len(series_list) // 2))

        avg_ret = df_combined.mean(axis=1)
        breadth = (df_combined > 0).sum(axis=1) / df_combined.notna().sum(axis=1)
        count = df_combined.notna().sum(axis=1)

        frame = pd.DataFrame({
            f"{sector}__ret": avg_ret,
            f"{sector}__breadth": breadth,
            f"{sector}__count": count,
        })
        result_frames.append(frame)

    if not result_frames:
        return pd.DataFrame()

    sector_df = pd.concat(result_frames, axis=1).sort_index()
    logger.info(
        "ì„¹í„° ì¼ë³„ ë°ì´í„°: %dê±°ë˜ì¼, %dê°œ ì„¹í„°",
        len(sector_df),
        len([c for c in sector_df.columns if c.endswith("__ret")]),
    )
    return sector_df


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. ë°±í…ŒìŠ¤íŒ… í•µì‹¬ ë¡œì§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def backtest_relay_pair(
    sector_df: pd.DataFrame,
    lead: str,
    follow: str,
    fire_threshold: float = 5.0,
    breadth_threshold: float = 0.7,
    lag_days: list[int] | None = None,
    min_samples: int = 3,
) -> dict:
    """ì„ í–‰â†’í›„í–‰ íŒ¨í„´ ë°±í…ŒìŠ¤íŒ….

    Returns:
        {lag1: {win_rate, avg_return, samples, confidence}, ..., best_lag}
    """
    if lag_days is None:
        lag_days = [1, 2, 3]

    lead_ret_col = f"{lead}__ret"
    lead_br_col = f"{lead}__breadth"
    follow_ret_col = f"{follow}__ret"

    # ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
    for col in [lead_ret_col, lead_br_col, follow_ret_col]:
        if col not in sector_df.columns:
            return {"error": f"ì»¬ëŸ¼ ì—†ìŒ: {col}", "samples": 0}

    # ë°œí™”ì¼ ì¶”ì¶œ
    fire_mask = (
        (sector_df[lead_ret_col] >= fire_threshold)
        & (sector_df[lead_br_col] >= breadth_threshold)
    )
    fire_dates = sector_df.index[fire_mask].tolist()

    if not fire_dates:
        return {
            "lead": lead, "follow": follow,
            "fire_dates": 0, "samples": 0,
            "error": "ë°œí™” ìƒ˜í”Œ ì—†ìŒ",
        }

    # ë˜ê·¸ë³„ í›„í–‰ ìˆ˜ìµë¥  ìˆ˜ì§‘
    dates_list = sector_df.index.tolist()
    lag_results = {}

    for lag in lag_days:
        returns = []
        cases = []

        for fire_date in fire_dates:
            try:
                idx = dates_list.index(fire_date)
                target_idx = idx + lag
                if target_idx >= len(dates_list):
                    continue
                target_date = dates_list[target_idx]

                follow_ret = sector_df.loc[target_date, follow_ret_col]
                lead_ret = sector_df.loc[fire_date, lead_ret_col]

                if pd.isna(follow_ret):
                    continue

                returns.append(float(follow_ret))
                cases.append({
                    "fire_date": fire_date.strftime("%Y-%m-%d"),
                    "target_date": target_date.strftime("%Y-%m-%d"),
                    "lead_ret": round(float(lead_ret), 2),
                    "follow_ret": round(float(follow_ret), 2),
                })
            except (ValueError, IndexError):
                continue

        n = len(returns)
        if n < min_samples:
            lag_results[f"lag{lag}"] = {
                "win_rate": 0, "avg_return": 0,
                "samples": n, "confidence": "LOW",
            }
            continue

        win_rate = round(sum(1 for r in returns if r > 0) / n * 100, 1)
        avg_return = round(float(np.mean(returns)), 2)
        med_return = round(float(np.median(returns)), 2)
        std_return = round(float(np.std(returns)), 2)

        if win_rate >= 65 and n >= 8:
            confidence = "HIGH"
        elif win_rate >= 55 and n >= 5:
            confidence = "MED"
        else:
            confidence = "LOW"

        # ì¼€ì´ìŠ¤ë¥¼ í›„í–‰ ìˆ˜ìµë¥  ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        cases.sort(key=lambda x: x["follow_ret"], reverse=True)

        lag_results[f"lag{lag}"] = {
            "win_rate": win_rate,
            "avg_return": avg_return,
            "med_return": med_return,
            "std_return": std_return,
            "samples": n,
            "confidence": confidence,
            "best_cases": cases[:3],
            "worst_cases": cases[-3:],
        }

    # ìµœì  ë˜ê·¸ ì„ íƒ (ìŠ¹ë¥  Ã— í‰ê· ìˆ˜ìµ ìµœëŒ€)
    best_lag = 1
    best_score = -999
    for lag in lag_days:
        key = f"lag{lag}"
        data = lag_results.get(key, {})
        if data.get("samples", 0) < min_samples:
            continue
        score = data.get("win_rate", 0) * max(data.get("avg_return", 0), 0.01)
        if score > best_score:
            best_score = score
            best_lag = lag

    return {
        "lead": lead,
        "follow": follow,
        "fire_dates": len(fire_dates),
        "best_lag": best_lag,
        **lag_results,
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. ì „ì²´ ì‹¤í–‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_full_backtest(
    fire_threshold: float = 5.0,
    breadth_threshold: float = 0.7,
    backtest_days: int = 504,
) -> dict:
    """ëª¨ë“  ìŠˆí¼ì„¹í„° ë¦´ë ˆì´ ìŒ ë°±í…ŒìŠ¤íŒ…."""

    print(f"\n{'=' * 60}")
    print(f"  ìŠˆí¼ì„¹í„° ë¦´ë ˆì´ ë°±í…ŒìŠ¤íŒ…")
    print(f"  ë°œí™” ê¸°ì¤€: +{fire_threshold}% & ìƒìŠ¹ë¹„ìœ¨ {breadth_threshold*100:.0f}%")
    print(f"  ê¸°ê°„: ìµœê·¼ {backtest_days}ê±°ë˜ì¼ (ì•½ {backtest_days/252:.1f}ë…„)")
    print(f"{'=' * 60}")

    # ì„¹í„° ë§¤í•‘ ë¡œë“œ
    ticker_to_sector = load_naver_sector_map()
    logger.info("ë„¤ì´ë²„ ì„¹í„°ë§µ: %dì¢…ëª©", len(ticker_to_sector))

    # ì„¹í„° ì¼ë³„ ë“±ë½ë¥  ë¹Œë“œ
    sector_df = build_sector_daily_returns(ticker_to_sector)
    if sector_df.empty:
        print("  ë°ì´í„° ë¶€ì¡±!")
        return {}

    # ìµœê·¼ Nê±°ë˜ì¼ë§Œ
    sector_df = sector_df.tail(backtest_days)
    logger.info("ë°±í…ŒìŠ¤íŒ… ê¸°ê°„: %s ~ %s", sector_df.index[0].strftime("%Y-%m-%d"),
                sector_df.index[-1].strftime("%Y-%m-%d"))

    # ë¦´ë ˆì´ ìŒ ë°±í…ŒìŠ¤íŒ…
    all_results = {}

    for super_name, config in SUPER_SECTORS.items():
        print(f"\nâ–£ [{super_name}]")
        all_results[super_name] = {}

        for lead, follow in config["relay_pairs"]:
            result = backtest_relay_pair(
                sector_df, lead, follow,
                fire_threshold=fire_threshold,
                breadth_threshold=breadth_threshold,
            )
            all_results[super_name][f"{lead}â†’{follow}"] = result

            # ìš”ì•½ ì¶œë ¥
            best_lag = result.get("best_lag", 1)
            lag_data = result.get(f"lag{best_lag}", {})
            wr = lag_data.get("win_rate", 0)
            ret = lag_data.get("avg_return", 0)
            conf = lag_data.get("confidence", "?")
            n = lag_data.get("samples", 0)
            fire_n = result.get("fire_dates", 0)

            conf_icon = {"HIGH": "ğŸŸ¢", "MED": "ğŸŸ¡", "LOW": "ğŸ”´"}.get(conf, "âš«")
            print(
                f"  {lead:<16} â†’ {follow:<16} "
                f"ë°œí™”{fire_n:>3}íšŒ  "
                f"ë˜ê·¸{best_lag}ì¼  "
                f"ìŠ¹ë¥ {wr:>5.1f}%  "
                f"í‰ê· {ret:>+6.2f}%  "
                f"{conf_icon}[{conf}] n={n}"
            )

    return all_results


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. ì €ì¥ + ìš”ì•½
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def save_patterns(results: dict, fire_threshold: float,
                  breadth_threshold: float, backtest_days: int):
    """relay_patterns.json ì €ì¥."""
    DATA_DIR.mkdir(parents=True, exist_ok=True)
    path = DATA_DIR / "relay_patterns.json"

    payload = {
        "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M"),
        "fire_threshold": fire_threshold,
        "breadth_threshold": breadth_threshold,
        "backtest_days": backtest_days,
        "super_sectors": results,
    }
    with open(path, "w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2, default=str)

    logger.info("íŒ¨í„´ ì €ì¥ â†’ %s", path)
    return path


def print_summary(results: dict):
    """HIGH/MED ì‹ ë¢°ë„ íŒ¨í„´ ìš”ì•½."""
    print(f"\n{'=' * 70}")
    print(f"  ë¦´ë ˆì´ íŒ¨í„´ ìš”ì•½ (MED ì´ìƒë§Œ)")
    print(f"{'=' * 70}")
    print(f"  {'ìŠˆí¼ì„¹í„°':<10} {'ì„ í–‰â†’í›„í–‰':<35} {'ë˜ê·¸':>3} {'ìŠ¹ë¥ ':>6} {'í‰ê· ':>7} {'ì‹ ë¢°ë„'}")
    print(f"  {'â”€' * 65}")

    found = 0
    for super_name, pairs in results.items():
        for pair_name, data in pairs.items():
            best_lag = data.get("best_lag", 1)
            lag_data = data.get(f"lag{best_lag}", {})
            conf = lag_data.get("confidence", "")
            if conf not in ("HIGH", "MED"):
                continue

            wr = lag_data.get("win_rate", 0)
            ret = lag_data.get("avg_return", 0)
            n = lag_data.get("samples", 0)
            icon = "ğŸŸ¢" if conf == "HIGH" else "ğŸŸ¡"

            print(
                f"  {super_name:<10} {pair_name:<35} "
                f"{best_lag}ì¼ {wr:>5.1f}% {ret:>+6.2f}%  "
                f"{icon} {conf} (n={n})"
            )
            found += 1

    if found == 0:
        print("  MED ì´ìƒ íŒ¨í„´ ì—†ìŒ (ë°œí™” ê¸°ì¤€ ì™„í™” í•„ìš” ê°€ëŠ¥)")

    print(f"{'=' * 70}\n")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    parser = argparse.ArgumentParser(description="ìŠˆí¼ì„¹í„° ë¦´ë ˆì´ ë°±í…ŒìŠ¤íŒ…")
    parser.add_argument("--threshold", type=float, default=3.5,
                        help="ë°œí™” ê¸°ì¤€ ë“±ë½ë¥  (ê¸°ë³¸ 3.5%%)")
    parser.add_argument("--breadth", type=float, default=0.6,
                        help="ë°œí™” ê¸°ì¤€ ìƒìŠ¹ë¹„ìœ¨ (ê¸°ë³¸ 0.6)")
    parser.add_argument("--days", type=int, default=504,
                        help="ë°±í…ŒìŠ¤íŒ… ê¸°ê°„ ê±°ë˜ì¼ (ê¸°ë³¸ 504=ì•½2ë…„)")
    args = parser.parse_args()

    results = run_full_backtest(
        fire_threshold=args.threshold,
        breadth_threshold=args.breadth,
        backtest_days=args.days,
    )

    if results:
        save_patterns(results, args.threshold, args.breadth, args.days)
        print_summary(results)
        print("  relay_patterns.json ìƒì„± ì™„ë£Œ.")
        print("  â†’ sector_relay_engine.pyê°€ ì´ ë°ì´í„°ë¥¼ ì°¸ì¡°í•©ë‹ˆë‹¤.")


if __name__ == "__main__":
    main()
