"""
Step 1: data_collector.py â€” KOSPI/KOSDAQ ì „ì¢…ëª© OHLCV + íˆ¬ìì ë§¤ë§¤ë™í–¥ ìˆ˜ì§‘

ë°ì´í„° ì†ŒìŠ¤: pykrx (KRX ê³µì‹ ë°ì´í„°, API í‚¤ ë¶ˆí•„ìš”)
ê¸°ê°„: settings.yamlì˜ backtest.start_date ~ end_date
ì €ì¥: data/raw/{ticker}.parquet
"""

import logging
import time
from pathlib import Path

import pandas as pd
import yaml
from tqdm import tqdm

logger = logging.getLogger(__name__)

# â”€â”€ pykrx import (ë¡œì»¬ ì‹¤í–‰ ì‹œ ì‚¬ìš©) â”€â”€
try:
    from pykrx import stock as krx
    PYKRX_AVAILABLE = True
except ImportError:
    PYKRX_AVAILABLE = False
    logger.warning("pykrx ë¯¸ì„¤ì¹˜. pip install pykrx ì‹¤í–‰ í•„ìš”")


class DataCollector:
    """KRXì—ì„œ ì „ì¢…ëª© OHLCV, íˆ¬ìì ë§¤ë§¤ë™í–¥, ê¸°ë³¸ í€ë”ë©˜íƒˆ ìˆ˜ì§‘"""

    def __init__(self, config_path: str = "config/settings.yaml"):
        with open(config_path, encoding="utf-8") as f:
            self.config = yaml.safe_load(f)

        self.start_date = self.config["backtest"]["start_date"].replace("-", "")
        self.end_date = self.config["backtest"]["end_date"].replace("-", "")
        self.raw_dir = Path("data/raw")
        self.raw_dir.mkdir(parents=True, exist_ok=True)

        # ì´ë¯¸ ìˆ˜ì§‘ ì™„ë£Œëœ ì¢…ëª© (resume ìš©)
        self.completed = set()
        self._load_completed()

    def _load_completed(self):
        """ì´ë¯¸ ì €ì¥ëœ parquet íŒŒì¼ì—ì„œ ì™„ë£Œ í‹°ì»¤ ì¶”ì¶œ"""
        for f in self.raw_dir.glob("*.parquet"):
            ticker = f.stem  # ì˜ˆ: 005930
            self.completed.add(ticker)
        if self.completed:
            logger.info(f"ì´ë¯¸ ìˆ˜ì§‘ ì™„ë£Œ: {len(self.completed)}ì¢…ëª© (resume ëª¨ë“œ)")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1. ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def get_all_tickers(self) -> pd.DataFrame:
        """KOSPI + KOSDAQ ì „ì¢…ëª© í‹°ì»¤ì™€ ì¢…ëª©ëª… ë°˜í™˜"""
        if not PYKRX_AVAILABLE:
            raise RuntimeError("pykrx ë¯¸ì„¤ì¹˜")

        date = self.end_date
        tickers = []

        for market in ["KOSPI", "KOSDAQ"]:
            ticker_list = krx.get_market_ticker_list(date, market=market)
            for t in ticker_list:
                name = krx.get_market_ticker_name(t)
                tickers.append({
                    "ticker": t,
                    "name": name,
                    "market": market,
                })
            time.sleep(0.3)

        df = pd.DataFrame(tickers)
        logger.info(f"ì „ì²´ ì¢…ëª© ìˆ˜: {len(df)} (KOSPI: {len(df[df.market=='KOSPI'])}, KOSDAQ: {len(df[df.market=='KOSDAQ'])})")
        return df

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 2. ê°œë³„ ì¢…ëª© OHLCV ìˆ˜ì§‘
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def download_ohlcv(self, ticker: str) -> pd.DataFrame:
        """ì¼ë´‰ OHLCV + ê±°ë˜ëŒ€ê¸ˆ"""
        df = krx.get_market_ohlcv_by_date(
            self.start_date, self.end_date, ticker, adjusted=True
        )
        if df.empty:
            return df

        df.index.name = "date"
        df.columns = ["open", "high", "low", "close", "volume", "trading_value", "price_change"]
        return df

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 3. íˆ¬ììë³„ ë§¤ë§¤ë™í–¥
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def download_investor_trading(self, ticker: str) -> pd.DataFrame:
        """ê¸°ê´€/ì™¸êµ­ì¸/ê°œì¸ ìˆœë§¤ìˆ˜ ê¸ˆì•¡"""
        try:
            df = krx.get_market_trading_value_by_date(
                self.start_date, self.end_date, ticker
            )
            if df.empty:
                return df
            df.index.name = "date"
            # ì»¬ëŸ¼: ê¸°ê´€í•©ê³„, ê¸°íƒ€ë²•ì¸, ê°œì¸, ì™¸êµ­ì¸í•©ê³„, ì „ì²´
            # í•„ìš”í•œ ê²ƒë§Œ ì„ íƒ
            cols_needed = []
            for col in df.columns:
                if "ê¸°ê´€" in col or "ì™¸êµ­ì¸" in col or "ê°œì¸" in col:
                    cols_needed.append(col)
            if cols_needed:
                df = df[cols_needed]
            return df
        except Exception as e:
            logger.warning(f"{ticker} íˆ¬ìì ë§¤ë§¤ë™í–¥ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 4. ê¸°ë³¸ í€ë”ë©˜íƒˆ (PER, PBR, EPS ë“±)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def download_fundamental(self, ticker: str) -> pd.DataFrame:
        """Trailing PER, PBR, EPS, BPS ë“±"""
        try:
            df = krx.get_market_fundamental_by_date(
                self.start_date, self.end_date, ticker
            )
            if df.empty:
                return df
            df.index.name = "date"
            return df
        except Exception as e:
            logger.warning(f"{ticker} í€ë”ë©˜íƒˆ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 5. ì „ì¢…ëª© ì¼ê´„ ìˆ˜ì§‘
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def collect_all(self):
        """ì „ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘ + parquet ì €ì¥ (resume ì§€ì›)"""
        tickers_df = self.get_all_tickers()

        # ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì €ì¥
        tickers_df.to_csv("data/universe/all_tickers.csv", index=False, encoding="utf-8-sig")

        pending = [t for t in tickers_df["ticker"] if t not in self.completed]
        logger.info(f"ìˆ˜ì§‘ ëŒ€ìƒ: {len(pending)}ì¢…ëª© (ì´ë¯¸ ì™„ë£Œ: {len(self.completed)})")

        failed = []

        for ticker in tqdm(pending, desc="ğŸ“Š ë°ì´í„° ìˆ˜ì§‘"):
            try:
                # OHLCV
                ohlcv = self.download_ohlcv(ticker)
                if ohlcv.empty:
                    logger.debug(f"{ticker}: OHLCV ì—†ìŒ, ê±´ë„ˆëœ€")
                    continue
                time.sleep(0.5)

                # íˆ¬ìì ë§¤ë§¤ë™í–¥
                investor = self.download_investor_trading(ticker)
                time.sleep(0.5)

                # í€ë”ë©˜íƒˆ
                fundamental = self.download_fundamental(ticker)
                time.sleep(0.5)

                # ë³‘í•©
                combined = ohlcv.copy()
                if not investor.empty:
                    combined = combined.join(investor, how="left")
                if not fundamental.empty:
                    # í€ë”ë©˜íƒˆ ì»¬ëŸ¼ëª… ì¶©ëŒ ë°©ì§€
                    fund_cols = {c: f"fund_{c}" for c in fundamental.columns}
                    fundamental = fundamental.rename(columns=fund_cols)
                    combined = combined.join(fundamental, how="left")

                # ì €ì¥
                save_path = self.raw_dir / f"{ticker}.parquet"
                combined.to_parquet(save_path)
                self.completed.add(ticker)

            except Exception as e:
                logger.error(f"{ticker} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                failed.append(ticker)
                time.sleep(1)  # ì—ëŸ¬ ì‹œ ì¡°ê¸ˆ ë” ëŒ€ê¸°

        # ì‹¤íŒ¨ ì¢…ëª© ê¸°ë¡
        if failed:
            pd.Series(failed).to_csv("data/raw/failed_tickers.csv", index=False)
            logger.warning(f"ìˆ˜ì§‘ ì‹¤íŒ¨: {len(failed)}ì¢…ëª© â†’ data/raw/failed_tickers.csv")

        logger.info(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: {len(self.completed)}ì¢…ëª©")
        return self.completed


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìƒ˜í”Œ ë°ì´í„° ìƒì„± (pykrx ì—†ì„ ë•Œ í…ŒìŠ¤íŠ¸ìš©)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_sample_data(output_dir: str = "data/raw", n_stocks: int = 30, seed: int = 42):
    """
    ë°±í…ŒìŠ¤íŠ¸ ë¡œì§ ê²€ì¦ìš© í•©ì„± ë°ì´í„° ìƒì„±.
    ì‹¤ì œ í•œêµ­ ëŒ€í˜•ì£¼ ìŠ¤íƒ€ì¼ì˜ ê°€ê²© íŒ¨í„´ì„ ì‹œë®¬ë ˆì´ì…˜.
    """
    import numpy as np
    np.random.seed(seed)

    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # ëŒ€í˜•ì£¼ ëª¨ì˜ ì¢…ëª© (ì‹¤ì œ ì½”ë“œ/ì´ë¦„ì€ ìƒ˜í”Œ)
    sample_stocks = [
        ("005930", "ì‚¼ì„±ì „ì", "ë°˜ë„ì²´", 70000),
        ("000660", "SKí•˜ì´ë‹‰ìŠ¤", "ë°˜ë„ì²´", 120000),
        ("005380", "í˜„ëŒ€ì°¨", "ìë™ì°¨", 200000),
        ("051910", "LGí™”í•™", "í™”í•™", 500000),
        ("006400", "ì‚¼ì„±SDI", "ë°°í„°ë¦¬", 400000),
        ("035420", "NAVER", "IT", 300000),
        ("035720", "ì¹´ì¹´ì˜¤", "IT", 60000),
        ("068270", "ì…€íŠ¸ë¦¬ì˜¨", "ë°”ì´ì˜¤", 180000),
        ("105560", "KBê¸ˆìœµ", "ì€í–‰", 60000),
        ("055550", "ì‹ í•œì§€ì£¼", "ì€í–‰", 40000),
        ("003550", "LG", "ê¸°íƒ€", 80000),
        ("066570", "LGì „ì", "ê¸°íƒ€", 100000),
        ("012330", "í˜„ëŒ€ëª¨ë¹„ìŠ¤", "ìë™ì°¨", 230000),
        ("028260", "ì‚¼ì„±ë¬¼ì‚°", "ê±´ì„¤", 130000),
        ("032830", "ì‚¼ì„±ìƒëª…", "ê¸°íƒ€", 80000),
        ("009150", "ì‚¼ì„±ì „ê¸°", "ë°˜ë„ì²´", 150000),
        ("017670", "SKí…”ë ˆì½¤", "í†µì‹ ", 50000),
        ("030200", "KT", "í†µì‹ ", 35000),
        ("034730", "SK", "ê¸°íƒ€", 170000),
        ("010130", "ê³ ë ¤ì•„ì—°", "ì² ê°•", 500000),
        ("036570", "ì—”ì”¨ì†Œí”„íŠ¸", "IT", 250000),
        ("003670", "í¬ìŠ¤ì½”í“¨ì²˜ì— ", "ë°°í„°ë¦¬", 300000),
        ("086790", "í•˜ë‚˜ê¸ˆìœµì§€ì£¼", "ì€í–‰", 45000),
        ("018260", "ì‚¼ì„±ì—ìŠ¤ë””ì—ìŠ¤", "IT", 150000),
        ("011170", "ë¡¯ë°ì¼€ë¯¸ì¹¼", "í™”í•™", 200000),
        ("096770", "SKì´ë…¸ë² ì´ì…˜", "í™”í•™", 150000),
        ("015760", "í•œêµ­ì „ë ¥", "ê¸°íƒ€", 25000),
        ("000270", "ê¸°ì•„", "ìë™ì°¨", 90000),
        ("033780", "KT&G", "ì‹í’ˆ", 90000),
        ("316140", "ìš°ë¦¬ê¸ˆìœµì§€ì£¼", "ì€í–‰", 14000),
    ]

    stocks = sample_stocks[:n_stocks]
    dates = pd.bdate_range("2019-01-02", "2024-12-30")

    sector_map = {}
    for ticker, name, sector, _ in stocks:
        sector_map[ticker] = {"name": name, "sector": sector}

    for ticker, name, sector, base_price in tqdm(stocks, desc="ğŸ“Š ìƒ˜í”Œ ë°ì´í„° ìƒì„±"):
        n_days = len(dates)

        # ê°€ê²© ì‹œë®¬ë ˆì´ì…˜: ì¶”ì„¸ + ë³€ë™ì„± + ì‚¬ì´í´
        trend = np.random.uniform(-0.0001, 0.0003)  # ì¼ê°„ ì¶”ì„¸
        volatility = np.random.uniform(0.015, 0.035)  # ì¼ê°„ ë³€ë™ì„±

        # ëœë¤ì›Œí¬ + í‰ê· íšŒê·€ ì„±ë¶„
        returns = np.random.normal(trend, volatility, n_days)
        # ì‚¬ì´í´ ì¶”ê°€ (6ê°œì›” ì£¼ê¸°)
        cycle = 0.15 * np.sin(np.linspace(0, 8 * np.pi, n_days))
        cumulative = np.cumsum(returns) + cycle

        close = base_price * np.exp(cumulative)
        close = np.maximum(close, base_price * 0.3)  # ìµœì†Œê°€ ë³´ì¥

        # OHLCV ìƒì„±
        daily_range = close * np.random.uniform(0.005, 0.03, n_days)
        high = close + daily_range * np.random.uniform(0.3, 1.0, n_days)
        low = close - daily_range * np.random.uniform(0.3, 1.0, n_days)
        open_price = low + (high - low) * np.random.uniform(0.2, 0.8, n_days)

        # ê±°ë˜ëŸ‰: ê¸°ë³¸ + ë³€ë™ (ê°€ê²© ê¸‰ë³€ ì‹œ ê±°ë˜ëŸ‰ ì¦ê°€)
        base_vol = np.random.uniform(500000, 5000000)
        vol_noise = np.random.lognormal(0, 0.5, n_days)
        price_change = np.abs(np.diff(close, prepend=close[0])) / close
        vol_spike = 1 + price_change * 30  # ê°€ê²© ë³€ë™ í´ìˆ˜ë¡ ê±°ë˜ëŸ‰ ì¦ê°€
        volume = (base_vol * vol_noise * vol_spike).astype(int)
        trading_value = (volume * close).astype(int)

        # íˆ¬ìì ë§¤ë§¤ë™í–¥ (ê¸°ê´€/ì™¸êµ­ì¸/ê°œì¸)
        inst_base = np.random.normal(0, trading_value * 0.1)
        foreign_base = np.random.normal(0, trading_value * 0.08)
        personal = -(inst_base + foreign_base)  # ì œë¡œì„¬

        # í€ë”ë©˜íƒˆ (Trailing PER, PBR, EPS)
        sector_per_map = {
            "ë°˜ë„ì²´": 15, "ìë™ì°¨": 7, "ë°°í„°ë¦¬": 25, "ë°”ì´ì˜¤": 30,
            "ì€í–‰": 5.5, "í™”í•™": 10, "ì² ê°•": 6, "IT": 18,
            "í†µì‹ ": 10, "ê±´ì„¤": 7, "ì‹í’ˆ": 14, "ê¸°íƒ€": 11,
        }
        base_per = sector_per_map.get(sector, 11)
        per_series = base_per + np.random.normal(0, base_per * 0.15, n_days)
        per_series = np.maximum(per_series, 2)  # ìµœì†Œ PER 2

        eps_series = close / per_series
        pbr_series = np.random.uniform(0.5, 3.0, n_days) + np.random.normal(0, 0.1, n_days)

        df = pd.DataFrame({
            "open": np.round(open_price).astype(int),
            "high": np.round(high).astype(int),
            "low": np.round(low).astype(int),
            "close": np.round(close).astype(int),
            "volume": volume,
            "trading_value": trading_value,
            "price_change": np.round(np.diff(close, prepend=close[0])).astype(int),
            "ê¸°ê´€í•©ê³„": np.round(inst_base).astype(int),
            "ì™¸êµ­ì¸í•©ê³„": np.round(foreign_base).astype(int),
            "ê°œì¸": np.round(personal).astype(int),
            "fund_BPS": np.round(close * np.random.uniform(0.5, 1.5, n_days)).astype(int),
            "fund_PER": np.round(per_series, 2),
            "fund_PBR": np.round(pbr_series, 2),
            "fund_EPS": np.round(eps_series).astype(int),
            "fund_DIV": np.round(np.random.uniform(0.5, 4.0, n_days), 2),
            "fund_DPS": np.round(close * np.random.uniform(0.005, 0.03, n_days)).astype(int),
        }, index=dates[:n_days])
        df.index.name = "date"

        save_path = output_dir / f"{ticker}.parquet"
        df.to_parquet(save_path)

    # ì¢…ëª© ë©”íƒ€ì •ë³´ ì €ì¥
    universe_dir = Path("data/universe")
    universe_dir.mkdir(parents=True, exist_ok=True)

    meta = pd.DataFrame([
        {"ticker": t, "name": n, "market": "KOSPI", "sector": s, "base_price": p}
        for t, n, s, p in stocks
    ])
    meta.to_csv(universe_dir / "all_tickers.csv", index=False, encoding="utf-8-sig")
    meta.to_csv(universe_dir / "sector_map.csv", index=False, encoding="utf-8-sig")

    logger.info(f"âœ… ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ: {n_stocks}ì¢…ëª©")
    return meta


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

    if PYKRX_AVAILABLE:
        collector = DataCollector()
        collector.collect_all()
    else:
        print("âš ï¸ pykrx ë¯¸ì„¤ì¹˜ â†’ ìƒ˜í”Œ ë°ì´í„°ë¡œ ëŒ€ì²´ ìƒì„±")
        generate_sample_data()
